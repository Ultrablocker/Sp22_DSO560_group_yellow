{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSO 560 Natural Language Processing Final Project\n",
    "\n",
    "### Team members: Tanner Curley, Shao Xuan Chew, Robert Zhu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo: overall code structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform lemmatization (not recommended when using any pretrained embedding)\n",
    "LEMMA = False\n",
    "# size of the vocab for\n",
    "VOCAB_SIZE = 20000\n",
    "# for self attention\n",
    "DATA_POINTS = 10\n",
    "DIMENSIONS = 240\n",
    "SEQUENCE_LENGTH = 4\n",
    "# use gpu\n",
    "USE_GPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7928286284658792753\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7806648320\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8733136223327924833\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:07:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, LSTM, Flatten, concatenate, Activation, RepeatVector, Permute\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from keras_self_attention import SeqSelfAttention\n",
    "from random import randint\n",
    "from numpy import array, argmax, asarray, zeros\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from textacy import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>product</th>\n",
       "      <th>narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>purchase order day shipping amount receive pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>forwarded message date tue subject please inve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>retail_banking</td>\n",
       "      <td>forwarded message cc sent friday pdt subject f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>payment history missing credit report speciali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>payment history missing credit report made mis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           product  \\\n",
       "0           0       credit_card   \n",
       "1           1       credit_card   \n",
       "2           2    retail_banking   \n",
       "3           3  credit_reporting   \n",
       "4           4  credit_reporting   \n",
       "\n",
       "                                           narrative  \n",
       "0  purchase order day shipping amount receive pro...  \n",
       "1  forwarded message date tue subject please inve...  \n",
       "2  forwarded message cc sent friday pdt subject f...  \n",
       "3  payment history missing credit report speciali...  \n",
       "4  payment history missing credit report made mis...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('complaints_processed.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaint_types = list(df['product'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(complaint_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162421, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "credit_reporting       91179\n",
       "debt_collection        23150\n",
       "mortgages_and_loans    18990\n",
       "credit_card            15566\n",
       "retail_banking         13536\n",
       "Name: product, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the dataset is imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocessing\n",
    "    1. remove hyphens and accents\n",
    "    2. create customized stopwords list and remove stopwords\n",
    "    3. regex cleaning\n",
    "    <!-- 4. typo correction with textblob -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['narrative'] = df['narrative'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = preprocessing.make_pipeline(\n",
    "    preprocessing.normalize.hyphenated_words,\n",
    "    preprocessing.remove.accents,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(stopwords.words('english'))\n",
    "# removing some negative words from stopwords list\n",
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "nltk_stopwords.remove('below')\n",
    "nltk_stopwords.remove(\"aren't\")\n",
    "nltk_stopwords.remove('couldn')\n",
    "nltk_stopwords.remove(\"couldn't\")\n",
    "nltk_stopwords.remove(\"didn't\")\n",
    "nltk_stopwords = list(nltk_stopwords)\n",
    "# add some abstract terms\n",
    "nltk_stopwords.append('like')\n",
    "nltk_stopwords.append('please')\n",
    "\n",
    "nltk_stopwords = set(nltk_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Robert\\AppData\\Local\\Temp\\ipykernel_22224\\868481445.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['narrative'] = df['narrative'].str.replace(r'\\b([a-z]|[A-Z]){15,}\\b', '', case=False)\n"
     ]
    }
   ],
   "source": [
    "# removing all words with more than 15 digits\n",
    "df['narrative'] = df['narrative'].str.replace(r'\\b([a-z]|[A-Z]){15,}\\b', '', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Robert\\AppData\\Local\\Temp\\ipykernel_22224\\1200782744.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['narrative'] = df['narrative'].str.replace(r'(.)\\1{3,}?', '', case=False)\n"
     ]
    }
   ],
   "source": [
    "# removing all characters that appear more than 2 times\n",
    "df['narrative'] = df['narrative'].str.replace(r'(.)\\1{3,}?', '', case=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U textblob\n",
    "# !python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spelling_correction(sentence: str):\n",
    "    sentence = str(sentence)\n",
    "    to_ret = TextBlob(sentence)\n",
    "    to_ret = str(to_ret.correct())\n",
    "    return to_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['narrative'] = df['narrative'].apply(spelling_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(str(sentence)))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LEMMA:\n",
    "    df['narrative'] = df['narrative'].apply(lemmatize_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['product']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. model preparation\n",
    "    1. tokenize\n",
    "    2. integer encoding\n",
    "    3. glove vectors\n",
    "    4. embedding matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize text\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "tokenizer.fit_on_texts(df['narrative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encoding\n",
    "from typing import List\n",
    "def get_max_token_length_per_doc(docs: List[List[str]])-> int:\n",
    "    return max(list(map(lambda x: len(x.split()), docs)))\n",
    "\n",
    "# get the max length in terms of token length\n",
    "max_length = get_max_token_length_per_doc(df['narrative'])\n",
    "\n",
    "\n",
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "MAX_SEQUENCE_LENGTH = 300\n",
    "# integer encode the documents\n",
    "encoded_docs = integer_encode_documents(df['narrative'], tokenizer)\n",
    "# this is a list of lists, the numbers represent the index position of that word.\n",
    "# for instance, 33 means the 33rd word in the vocabulary\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# glove vectors\n",
    "def load_glove_vectors():\n",
    "    embeddings_index = {}\n",
    "    with open('glove\\glove.6B.100d.txt') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "embeddings_index = load_glove_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= VOCAB_SIZE:\n",
    "        break\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. model definition\n",
    "    1. LSTM\n",
    "    2. Bi-directional LSTM\n",
    "    3. RNN\n",
    "    4. BERT\n",
    "    5. Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.recurrent import SimpleRNN, LSTM\n",
    "from keras.layers import Flatten, Masking\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "def make_lstm_classification_model(plot=False):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "    # model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "    model.add(CuDNNLSTM(units=64, input_shape=(1, MAX_SEQUENCE_LENGTH)))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer= \"adam\", metrics=['accuracy'])\n",
    "    # summarize the model\n",
    "    model.summary()\n",
    "    \n",
    "    if plot:\n",
    "        plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 64)                42496     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 2,043,621\n",
      "Trainable params: 43,621\n",
      "Non-trainable params: 2,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_lstm_classification_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "transfomed_labels = encoder.fit_transform(labels)\n",
    "# print(transfomed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, transfomed_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, gpu = USE_GPU):\n",
    "    if not USE_GPU:\n",
    "        with tf.device('/cpu:0'):\n",
    "            history = model.fit(padded_docs, transfomed_labels, validation_split = 0.1, epochs=10, verbose=1)\n",
    "    else:\n",
    "            history = model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=10, verbose=1)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4569/4569 [==============================] - 1144s 250ms/step - loss: 0.4048 - accuracy: 0.8565 - val_loss: 0.4352 - val_accuracy: 0.8420\n",
      "Epoch 2/10\n",
      "4569/4569 [==============================] - 1174s 257ms/step - loss: 0.3645 - accuracy: 0.8703 - val_loss: 0.4136 - val_accuracy: 0.8484\n",
      "Epoch 3/10\n",
      "4569/4569 [==============================] - 1215s 266ms/step - loss: 0.3386 - accuracy: 0.8794 - val_loss: 0.4127 - val_accuracy: 0.8514\n",
      "Epoch 4/10\n",
      "4569/4569 [==============================] - 1249s 273ms/step - loss: 0.3188 - accuracy: 0.8857 - val_loss: 0.4087 - val_accuracy: 0.8527\n",
      "Epoch 5/10\n",
      "4569/4569 [==============================] - 1286s 281ms/step - loss: 0.3007 - accuracy: 0.8932 - val_loss: 0.4018 - val_accuracy: 0.8561\n",
      "Epoch 6/10\n",
      "4569/4569 [==============================] - 26073s 6s/step - loss: 0.2855 - accuracy: 0.8980 - val_loss: 0.4208 - val_accuracy: 0.8532\n",
      "Epoch 7/10\n",
      "4569/4569 [==============================] - 1386s 303ms/step - loss: 0.2729 - accuracy: 0.9029 - val_loss: 0.4194 - val_accuracy: 0.8523\n",
      "Epoch 8/10\n",
      "4569/4569 [==============================] - 1405s 308ms/step - loss: 0.2606 - accuracy: 0.9074 - val_loss: 0.4389 - val_accuracy: 0.8493\n",
      "Epoch 9/10\n",
      "4569/4569 [==============================] - 1495s 327ms/step - loss: 0.2487 - accuracy: 0.9119 - val_loss: 0.4605 - val_accuracy: 0.8418\n",
      "Epoch 10/10\n",
      "4569/4569 [==============================] - 1487s 325ms/step - loss: 0.2379 - accuracy: 0.9154 - val_loss: 0.4680 - val_accuracy: 0.8398\n",
      "Epoch 1/10\n",
      " 326/4061 [=>............................] - ETA: 2:22:03 - loss: 0.2388 - accuracy: 0.9181"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Robert\\Desktop\\DSO560\\final_project\\main.ipynb Cell 40'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Robert/Desktop/DSO560/final_project/main.ipynb#ch0000040?line=2'>3</a>\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39m/cpu:0\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Robert/Desktop/DSO560/final_project/main.ipynb#ch0000040?line=3'>4</a>\u001b[0m         history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(padded_docs, transfomed_labels, validation_split \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Robert/Desktop/DSO560/final_project/main.ipynb#ch0000040?line=4'>5</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, validation_data\u001b[39m=\u001b[39;49m(X_test,y_test), epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/.conda/envs/tensorflow-gpu/lib/site-packages/keras/engine/training.py?line=1176'>1177</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/.conda/envs/tensorflow-gpu/lib/site-packages/keras/engine/training.py?line=1177'>1178</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/.conda/envs/tensorflow-gpu/lib/site-packages/keras/engine/training.py?line=1178'>1179</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/.conda/envs/tensorflow-gpu/lib/site-packages/keras/engine/training.py?line=1179'>1180</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/.conda/envs/tensorflow-gpu/lib/site-packages/keras/engine/training.py?line=1180'>1181</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/.conda/envs/tensorflow-gpu/lib/site-packages/keras/engine/training.py?line=1181'>1182</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/.conda/envs/tensorflow-gpu/lib/site-packages/keras/engine/training.py?line=1182'>1183</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> <a href='file:///c%3A/Users/Robert/.conda/envs/tensorflow-gpu/lib/site-packages/keras/engine/training.py?line=1183'>1184</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/.conda/envs/tensorflow-gpu/lib/site-packages/keras/engine/training.py?line=1184'>1185</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/.conda/envs/tensorflow-gpu/lib/site-packages/keras/engine/training.py?line=1185'>1186</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Users/Robert/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history = fit_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # From https://keras.io/visualization/\n",
    "\n",
    "\n",
    "def plot_performance(history):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# plot_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "def make_bi_lstm_classification_model(plot=False):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "    model.add(SpatialDropout1D(0.2)) #spatial dropout the whole channel to increase performance and prevent overfitting\n",
    "    model.add(Bidirectional(CuDNNLSTM(64, return_sequences=True)))\n",
    "    model.add(Bidirectional(CuDNNLSTM(32)))\n",
    "    model.add(Dropout(0.25)) #dropout to prevent overfitting\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer= \"adam\", metrics=['accuracy'])\n",
    "    # summarize the model\n",
    "    model.summary()\n",
    "    \n",
    "    if plot:\n",
    "        plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 300, 100)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 300, 128)          84992     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                41472     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 2,126,789\n",
      "Trainable params: 126,789\n",
      "Non-trainable params: 2,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = make_bi_lstm_classification_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4569/4569 [==============================] - 283s 62ms/step - loss: 0.5522 - accuracy: 0.8067 - val_loss: 0.4615 - val_accuracy: 0.8284\n",
      "Epoch 2/10\n",
      "4569/4569 [==============================] - 274s 60ms/step - loss: 0.4211 - accuracy: 0.8524 - val_loss: 0.4296 - val_accuracy: 0.8439\n",
      "Epoch 3/10\n",
      "4569/4569 [==============================] - 279s 61ms/step - loss: 0.3869 - accuracy: 0.8642 - val_loss: 0.4043 - val_accuracy: 0.8551\n",
      "Epoch 4/10\n",
      "4569/4569 [==============================] - 279s 61ms/step - loss: 0.3633 - accuracy: 0.8719 - val_loss: 0.3826 - val_accuracy: 0.8622\n",
      "Epoch 5/10\n",
      "4569/4569 [==============================] - 278s 61ms/step - loss: 0.3467 - accuracy: 0.8774 - val_loss: 0.3837 - val_accuracy: 0.8612\n",
      "Epoch 6/10\n",
      "4569/4569 [==============================] - 265s 58ms/step - loss: 0.3324 - accuracy: 0.8823 - val_loss: 0.3825 - val_accuracy: 0.8608\n",
      "Epoch 7/10\n",
      "4569/4569 [==============================] - 272s 59ms/step - loss: 0.3205 - accuracy: 0.8867 - val_loss: 0.3830 - val_accuracy: 0.8668\n",
      "Epoch 8/10\n",
      "4569/4569 [==============================] - 290s 63ms/step - loss: 0.3122 - accuracy: 0.8890 - val_loss: 0.3976 - val_accuracy: 0.8586\n",
      "Epoch 9/10\n",
      "4569/4569 [==============================] - 277s 61ms/step - loss: 0.3025 - accuracy: 0.8921 - val_loss: 0.3831 - val_accuracy: 0.8700\n",
      "Epoch 10/10\n",
      "4569/4569 [==============================] - 283s 62ms/step - loss: 0.2951 - accuracy: 0.8944 - val_loss: 0.3967 - val_accuracy: 0.8628\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history2 = fit_model(model2, gpu=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_performance(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN\n",
    "def make_rnn_classification_model(plot=False):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "    model.add(SimpleRNN(64))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer= \"adam\", metrics=['accuracy'])\n",
    "    # summarize the model\n",
    "    model.summary()\n",
    "    \n",
    "    if plot:\n",
    "        plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 300, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 64)                10560     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 2,010,885\n",
      "Trainable params: 10,885\n",
      "Non-trainable params: 2,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = make_rnn_classification_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4569/4569 [==============================] - 492s 108ms/step - loss: 1.2958 - accuracy: 0.5575 - val_loss: 1.2517 - val_accuracy: 0.5820\n",
      "Epoch 2/10\n",
      "4569/4569 [==============================] - 492s 108ms/step - loss: 1.2821 - accuracy: 0.5598 - val_loss: 1.2440 - val_accuracy: 0.5835\n",
      "Epoch 3/10\n",
      "4569/4569 [==============================] - 504s 110ms/step - loss: 1.2851 - accuracy: 0.5597 - val_loss: 1.2487 - val_accuracy: 0.5814\n",
      "Epoch 4/10\n",
      "4569/4569 [==============================] - 506s 111ms/step - loss: 1.2840 - accuracy: 0.5603 - val_loss: 1.2492 - val_accuracy: 0.5846\n",
      "Epoch 5/10\n",
      "4569/4569 [==============================] - 499s 109ms/step - loss: 1.2826 - accuracy: 0.5611 - val_loss: 1.2381 - val_accuracy: 0.5847\n",
      "Epoch 6/10\n",
      "4569/4569 [==============================] - 497s 109ms/step - loss: 1.2808 - accuracy: 0.5618 - val_loss: 1.2517 - val_accuracy: 0.5863\n",
      "Epoch 7/10\n",
      "4569/4569 [==============================] - 491s 107ms/step - loss: 1.2803 - accuracy: 0.5623 - val_loss: 1.2481 - val_accuracy: 0.5835\n",
      "Epoch 8/10\n",
      "4569/4569 [==============================] - 509s 111ms/step - loss: 1.2804 - accuracy: 0.5621 - val_loss: 1.2377 - val_accuracy: 0.5858\n",
      "Epoch 9/10\n",
      "4569/4569 [==============================] - 595s 130ms/step - loss: 1.2784 - accuracy: 0.5626 - val_loss: 1.2377 - val_accuracy: 0.5869\n",
      "Epoch 10/10\n",
      "4569/4569 [==============================] - 537s 118ms/step - loss: 1.2781 - accuracy: 0.5632 - val_loss: 1.2382 - val_accuracy: 0.5871\n"
     ]
    }
   ],
   "source": [
    "history3 = fit_model(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_self_attention import SeqSelfAttention\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Concatenate\n",
    "# model courtesy of Polignano et al.: https://dl.acm.org/doi/10.1145/3314183.3324983\n",
    "def make_bi_lstm_self_attention_classification_model(plot=False):\n",
    "    input = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "    model = Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False) (input)\n",
    "    # model = SpatialDropout1D(0.2) (model) #spatial dropout the whole channel to increase performance and prevent overfitting\n",
    "    bi = Bidirectional(CuDNNLSTM(64, return_sequences=True)) (model)\n",
    "    model = SeqSelfAttention(attention_activation='relu') (bi)\n",
    "    model = Conv1D(128, 5, activation='relu') (model)\n",
    "    model = MaxPooling1D() (model)\n",
    "    model = Dropout(0.2) (model) #dropout to prevent overfitting\n",
    "    model = Concatenate(axis=1)([model, bi])\n",
    "    model = GlobalMaxPooling1D() (model)\n",
    "    model = Dense(100, activation='softmax') (model)\n",
    "    model = Dropout(0.2) (model)\n",
    "    model = Dense(NUM_CLASSES, activation='softmax') (model)\n",
    "    # Compile the model\n",
    "    # model.compile(loss=\"categorical_crossentropy\", optimizer= \"adam\", metrics=['accuracy'])\n",
    "    m = keras.models.Model(inputs=[input], outputs=[model])\n",
    "    m.compile(loss=\"categorical_crossentropy\", optimizer= \"adam\", metrics=['accuracy'])\n",
    "    # summarize the model\n",
    "    m.summary()\n",
    "    \n",
    "    if plot:\n",
    "        plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)        (None, 300, 100)     2000000     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 300, 128)     84992       embedding_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "seq_self_attention_18 (SeqSelfA (None, 300, 128)     8257        bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 296, 128)     82048       seq_self_attention_18[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 148, 128)     0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 148, 128)     0           max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 448, 128)     0           dropout_25[0][0]                 \n",
      "                                                                 bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 128)          0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 100)          12900       global_max_pooling1d_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 100)          0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 5)            505         dropout_26[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,188,702\n",
      "Trainable params: 188,702\n",
      "Non-trainable params: 2,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = make_bi_lstm_self_attention_classification_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 184/4569 [>.............................] - ETA: 38:38 - loss: 1.4390 - accuracy: 0.5532"
     ]
    }
   ],
   "source": [
    "history4 = fit_model(model4, gpu=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
